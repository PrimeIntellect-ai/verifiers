# dummy-harbor-env

### Overview

- **Environment ID**: `dummy-harbor-env`
- **Short description**: Minimal Harbor environment for testing the CLI agent interception framework
- **Tags**: `dummy`, `testing`, `cli-agent`, `harbor`

### Datasets

- **Primary dataset**: Harbor-format tasks in `tasks/` directory
- **Source**: Bundled with environment
- **Tasks**: 1 dummy task (`hello-world`)

### Task

- **Type**: multi-turn (via HarborEnv)
- **Base class**: `HarborEnv` (extends `CliAgentEnv`)
- **Rubric overview**:
  - `harbor_reward`: Returns 1.0 if `/app/result.txt` contains "SUCCESS", 0.0 otherwise

### Quickstart

Run an evaluation with default settings:

```bash
uv run vf-eval dummy-harbor-env
```

Configure model and sampling:

```bash
uv run vf-eval dummy-harbor-env -m gpt-4.1-mini -n 1 -r 1
```

### How It Works

This environment demonstrates the HarborEnv/CliAgentEnv data flow:

1. **Harbor Task Loading**: Task is loaded from `tasks/hello-world/` with `task.toml`, `instruction.md`, and `tests/`
2. **Sandbox Creation**: A Docker sandbox is created with the task instruction uploaded
3. **Agent Execution**: A Python script is run that makes OpenAI API calls
4. **Interception**: API calls are intercepted by CliAgentEnv's HTTP proxy server (via Cloudflare tunnel)
5. **Data Flow**: Each intercepted API call triggers one rollout iteration:
   - Agent makes HTTP request -> intercepted by proxy server
   - Request queued -> `get_prompt_messages()` processes it
   - Response generated by model
   - Response returned to agent in sandbox
6. **Completion**: Agent writes "SUCCESS" to `/app/result.txt` when done
7. **Testing**: Harbor's `tests/test.sh` runs to compute reward based on result file

### Agent Script Details

The embedded agent script:

- Reads `OPENAI_BASE_URL` and `OPENAI_MODEL` from environment variables
- Reads task instruction from `/task/instruction.md` (Harbor format)
- Makes 4 OpenAI API calls in a loop with hardcoded environment messages
- Writes "SUCCESS" to `/app/result.txt` on completion

### Environment Arguments

| Argument          | Type                | Default            | Description                              |
| ----------------- | ------------------- | ------------------ | ---------------------------------------- |
| `dataset_path`    | `str \| Path`       | `./tasks`          | Path to Harbor-format tasks directory    |
| `tasks`           | `list[str] \| None` | `None`             | Specific task names to load (None = all) |
| `agent_workdir`   | `str`               | `/app`             | Working directory for agent in sandbox   |
| `docker_image`    | `str`               | `python:3.11-slim` | Docker image for sandbox                 |
| `timeout_seconds` | `float`             | `300.0`            | Overall rollout timeout                  |
| `request_timeout` | `float`             | `60.0`             | Per-request timeout                      |
| `max_turns`       | `int`               | `-1`               | Max turns (-1 = unlimited)               |

### Metrics

| Metric   | Meaning                                                    |
| -------- | ---------------------------------------------------------- |
| `reward` | 1.0 if test passes (SUCCESS in result file), 0.0 otherwise |
