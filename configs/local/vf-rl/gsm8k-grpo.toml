model = "Qwen/Qwen2.5-0.5B-Instruct"

[env]
id = "math_gdpo_exp"

[env.args]
advantage_mode = "grpo"

[inference]
gpus = 1


[trainer]
gpus = 3

[trainer.args]
lora_target_modules = "all-linear"
run_name = "gsm8k-grpo-0.5B"
micro_batch_size = 64
rollouts_per_example = 64
batch_size = 1024
max_steps = 500
max_seq_len = 2048
